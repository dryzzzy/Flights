{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Opis notatnika\n",
    " W poprzednich krokach pobraliśmy dane oraz przygotowaliśmy bazę `Postgres` na import. Głównym celem w tym notatniku jest  odpowiednie dostosowanie struktury danych z plików źródłowych do formatu zgodnego z `Postgres`, a następnie wgranie ich na nasz serwer. Dzięki temu w późniejszych krokach możemy niezależnie użyć danych do analizy czy raportowania.\n",
    " \n",
    " Ponownie wcielasz się w rolę Data Engineera, którego zadaniem jest zasilenie bay danych pobranymi danymi. Bez poprawnego załadowania danych nie będziesz w stanie dokonać analizy eksploracyjnej, która jest jednym z wymagań dostarczonych przez klienta.\n",
    "\n",
    " Przy wykonywaniu tego notebooka przydadzą się poniższe elementy kursu oraz materiały dodatkowe:\n",
    " * `SQL - analiza danych > Zjazd 1 - materiały dodatkowe > Export danych z DB > Python` - w celu użycia połączenia razem z `Pandas`,\n",
    " * https://docs.sqlalchemy.org/en/14/core/engines.html - w celu uzupełnienia konfiguracji `Pandas` do `PostgerSQL`,\n",
    " * https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_sql.html - eksport danych z `Pandas` na bazę danych.\n",
    "\n",
    " > Uwaga: Ze względu na wolumen danych zawarty w pliku `flight.csv`, wykonanie tego notatnika może zająć nawet kilkadziesiąt minut lub więcej!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Połączenie z bazą danych\n",
    "Tutaj uzupełnij konfigurację połączenia tworząc zmienne takie jak:\n",
    "- `username` - nazwa użytkownika bazy,\n",
    "- `password` - hasło do bazy,\n",
    "- `host` - adres naszej bazy danych, jeśli baza jest postawiona na naszej maszynie wtedy będzie to po prostu `localhost`,\n",
    "- `database` - nazwa bazy danych np. `postgresql`\n",
    "- `port` - domyślnie `5432`\n",
    "\n",
    "> Przetrzymywanie hasła w ten sposób nie jest bezpieczne, co było zaznaczane w trakcie kursu. Lepszym sposobem jest używanie zmiennych środowiskowych, ale na nasze potrzeby nie jest to potrzebne. Dla osób chcących zapoznać się z taką formą zalecamy ten artykuł - [klik](https://developer.vonage.com/blog/21/10/01/python-environment-variables-a-primer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install mysql-connector-python\n",
    "!pip install chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import mysql.connector as sql\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.engine import URL\n",
    "import chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "username = 'postgres'\n",
    "password = 'postgres'\n",
    "host = 'localhost'\n",
    "database = 'airlines'\n",
    "port = 5432"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Z pomocą artykułu [click](https://docs.sqlalchemy.org/en/14/core/engines.html) stwórz zmienne `url` oraz `engine`. Zgodnie z dokumentacją `Pandas`, zmienna `engine` będzie potrzebna, by móc wyeksportować dane na serwer `SQL`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W tym miejscu stwórz zmienne `url` oraz `engine`\n",
    "> Wskazówka: Zmienna `url` powinna być stworzona zgodnie ze schematem jak we wcześniej podanym artykule, jednak powinna używać zmiennych zdefiniowanych wyżej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = f'postgresql://{username}:{password}@{host}:{port}/{database}'\n",
    "engine = create_engine(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Załadowanie ramek do obszaru roboczego\n",
    " Uzupełnij implementacje funkcji `load_raw_data`, która przyjmuje jeden parametr:\n",
    " * `file_name` - nazwa pliku do zaczytania\n",
    " Jej zadaniem jest wczytanie surowego pliku, zmodyfikowanie nazw kolumn z `NAZWA_KOLUMNY` na `nazwa_kolumny` oraz zwrócenie tak zmodyfikowanej ramki danych\n",
    "\n",
    " Mogą się przydać poniższe element kursu:\n",
    " - `Python-Analiza danych -> Dzień 5 - Pandas -> Obróbka danych - częsć 1`\n",
    " - `Python-Analiza danych -> Przygotowanie do zjazdu 3 -> Wstęp do Pandas -> Wczytywanie danych do Pandas` - jakie kodowanie mają pliki?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def detect_encoding(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        result = chardet.detect(f.read())\n",
    "    encoding = result['encoding']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_data(file_name):\n",
    "    file_path = f'../data/raw/{file_name}.csv'\n",
    "    encoding = detect_encoding(file_path)\n",
    "    df = pd.read_csv(file_path, encoding='utf-8')\n",
    "    df.columns = [col.lower() for col in df.columns]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Zaczytanie poszczególnych plików do ramek\n",
    "\n",
    " W tym miejscu zaczytaj poszczególne pliki do ramek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['aircraft', 'airport_list', 'airport_weather', 'flight']\n",
    "dfs = {}\n",
    "for file_name in files:\n",
    "    df = load_raw_data(file_name)\n",
    "    dfs[file_name] = load_raw_data(file_name)\n",
    "    print(f\"DataFrame for {file_name} loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aircraft_df = dfs['aircraft']\n",
    "flight_df = dfs['flight']\n",
    "airport_weather_df = dfs['airport_weather']\n",
    "airport_list_df = dfs['airport_list']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Eksport danych na bazę\n",
    " Zapoznaj się z dokumentacją metody `Pandas` - [to_sql](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_sql.html), której zadaniem jest wyeksportowanie ramki na bazę danych.\n",
    " Zwróć szczególną uwagę na poniższe parametry:\n",
    " * `if_exists` - jak ma się zachować metoda, gdy ładuje dane na bazę,\n",
    " * `con` - połączenie do bazy,\n",
    " * `name` - nazwa tabeli, do której ramka ma zostać wgrana,\n",
    " * `index` - czy dodawać index z ramki jako kolumnę,\n",
    " * `chunksize` - maksymalna liczba wierszy wgrywana za jednym razem.\n",
    "\n",
    " > **Uwaga:** \n",
    " > Przed eksportem upewnij się, że tabela jest pusta. Zwróć uwagę na pewną subtelną różnicę pomiędzy wyglądem ramki oraz tabeli docelowej na bazie danych.\n",
    "\n",
    "Następnie uzupełnij implementację metody `export_table_to_db`, która przyjmuje dwa argumenty:\n",
    " * `df` - ramka danych do eksportu,\n",
    " * `table_name` - nazwa ramki na bazie.\n",
    "\n",
    "Zalecamy, aby dodać do metody informację, która ramka jest aktualnie ładowana np.:\n",
    " `Loading data into {table_name}...`\n",
    " > Ze względu na rozmiar ramki `flight_df`, proces ten może potrwać nawet kilkadziesiąt minut! Z tego względu, na potrzeby testów, zalecamy przekazanie do procedury `export_table_to_db` np. pierwszych 5 wierszy, aby sprawdzić, czy działa, a potem wgrać cały zestaw danych - pamiętając o upszednim usunięciu tamtych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_table_to_db(df, table_name):\n",
    "    print(f'Loading data into {table_name}...')\n",
    "    df.to_sql(\n",
    "        name = table_name,\n",
    "        con = engine,\n",
    "        if_exists = 'append',\n",
    "        index = False,\n",
    "    )\n",
    "    print(f\"Data loaded into {table_name} successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Wgrywanie danych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Wgranie `aircraft_df` do tabeli `aircraft`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with engine.connect() as connection:\n",
    "    connection.execute(text(\"TRUNCATE TABLE aircraft;\"))\n",
    "\n",
    "print(\"Table aircraft has been truncated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export_table_to_db(aircraft_df, 'aircraft')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Wgranie `airport_weather_df` do tabeli `airport_weather`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with engine.connect() as connection:\n",
    "    connection.execute(text(\"TRUNCATE TABLE airport_weather;\"))\n",
    "\n",
    "print(\"Table airport_weather has been truncated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_table_to_db(airport_weather_df, 'airport_weather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Wgranie `flight_df` do tabeli `flight`\n",
    " > Wykonanie tej komórki może zająć kilka-kilknaście minut za względu na ilość danych w ramce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with engine.connect() as connection:\n",
    "    connection.execute(text(\"TRUNCATE TABLE flight;\"))\n",
    "\n",
    "print(\"Table flight has been truncated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_table_to_db(flight_df, 'flight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Wgranie `airport_list_df` do tabeli `airport_list`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with engine.connect() as connection:\n",
    "    connection.execute(text(\"TRUNCATE TABLE airport_list;\"))\n",
    "\n",
    "print(\"Table airport_list has been truncated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_table_to_db(airport_list_df, 'airport_list')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Sprawdzenie poprawności wykonania notatnika\n",
    " Uruchom kod poniżej, aby sprawdzić, czy ta część została poprawnie wykonana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data_export(table_name, expected_count, expected_schema):\n",
    "    real_count = pd.read_sql(f\"SELECT COUNT(*) as cnt FROM {table_name}\", engine).iloc[0][0]\n",
    "    \n",
    "    real_schema = pd.read_sql(f\"SELECT * FROM {table_name} LIMIT 0\", engine)\n",
    "    real_schema = set(real_schema.columns)\n",
    "\n",
    "    expected_schema = set(expected_schema)\n",
    "\n",
    "    diff = real_schema.symmetric_difference(expected_schema)\n",
    "\n",
    "    assert len(diff) == 0, ('Nie zgadzają się kolumny tabel....'\n",
    "    f'\\tOczekiwano: {expected_schema}'\n",
    "    f'\\tOtrzymano: {real_schema}'\n",
    "    f'\\tRóżnica: {diff}')\n",
    "\n",
    "    assert expected_count == real_count, \\\n",
    "        f'Nie zgadza się liczba wierszy, oczekiwano {expected_count}, otrzymano {real_count} - sprawdź, czy nie dane nie zostały wgrane do tabeli \"{table_name}\" więcej niż raz.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Sprawdzenie tabeli `aircraft`\n",
    " Uruchom kod poniżej, aby sprawdzić, czy ta część została poprawnie wykonana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aircraft_expected_count = 7383\n",
    "aircraft_expected_schema = ['id', 'manufacture_year', 'tail_num', 'number_of_seats']\n",
    "\n",
    "test_data_export('aircraft', aircraft_expected_count, aircraft_expected_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Sprawdzenie tabeli `airport_weather`\n",
    " Uruchom kod poniżej, aby sprawdzić, czy ta część została poprawnie wykonana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airport_weather_expected_count = 46227\n",
    "airport_weather_expected_schema = [\n",
    "       'id', 'station', 'name', 'date', 'awnd', 'prcp', 'snow', 'snwd', 'tavg', \n",
    "       'tmax', 'tmin', 'wdf2', 'wdf5', 'wsf2', 'wsf5', 'wt01', 'wt08', 'wt02',\n",
    "       'wt03', 'wt04', 'wt09', 'wt06', 'wt05', 'pgtm', 'wt10', 'wesd', 'sn32',\n",
    "       'sx32', 'psun', 'tsun', 'tobs', 'wt07', 'wt11', 'wt18']\n",
    "\n",
    "test_data_export('airport_weather', airport_weather_expected_count, airport_weather_expected_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Sprawdzenie tabeli `flight`\n",
    " Uruchom kod poniżej, aby sprawdzić, czy ta część została poprawnie wykonana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_expected_count = 1386121\n",
    "flight_expected_schema = [\n",
    "       'id', 'month', 'day_of_month', 'day_of_week', 'op_unique_carrier', 'tail_num',\n",
    "       'op_carrier_fl_num', 'origin_airport_id', 'dest_airport_id',\n",
    "       'crs_dep_time', 'dep_time', 'dep_delay_new', 'dep_time_blk',\n",
    "       'crs_arr_time', 'arr_time', 'arr_delay_new', 'arr_time_blk',\n",
    "       'cancelled', 'crs_elapsed_time', 'actual_elapsed_time', 'distance',\n",
    "       'distance_group', 'year', 'carrier_delay', 'weather_delay', 'nas_delay',\n",
    "       'security_delay', 'late_aircraft_delay']\n",
    "\n",
    "test_data_export('flight', flight_expected_count, flight_expected_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Sprawdzenie tabeli `airport_list`\n",
    " Uruchom kod poniżej, aby sprawdzić, czy ta część została poprawnie wykonana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airport_list_expected_count = 97\n",
    "airport_list_expected_schema = ['id', 'origin_airport_id', 'display_airport_name', 'origin_city_name', 'name']\n",
    "\n",
    "test_data_export('airport_list', airport_list_expected_count, airport_list_expected_schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = \"Wszystko wygląda OK :) Możesz przejść do kolejnego kroku.\"\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Podsumowanie\n",
    " W tym notatniku załadowaliśmy pobrane wcześniej pliki na bazę danych. Dzięki temu stworzyliśmy centralne miejsce ich magazynowania, co wykorzystamy zarówno przy analizie danych, jak i przy późniejszej budowie systemu raportowego."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "38d75d0df746d7f75dd34c5d1915af59cb55786647bd68b8d9064425d7680b12"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
